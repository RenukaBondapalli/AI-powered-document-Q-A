# ğŸ¤– AI-Powered Document Q&A

Upload any document and ask natural language questions to extract instant answers. This Retrieval-Augmented Generation (RAG) system uses:

- ğŸ§  Google Gemini 1.5 Flash as the LLM  
- ğŸŒ HuggingFace BGE Large embeddings  
- ğŸ” LangChain for retrieval-based Q&A  
- âš¡ In-memory Chroma vector store  
- ğŸ§¾ Supports `.pdf`, `.txt`, `.html` documents  
- ğŸ§  Built with Python + Flask

---

### ğŸ¥ Live Demo Video

[ğŸ‘‰ Click here to watch the demo](https://drive.google.com/file/d/1wkoR6cOAd2hJ1iNxeSCa_GyWoLhndMZl/view?usp=drivesdk)

---

## ğŸš€ Features

- Upload documents and process them in-memory
- Ask contextual questions based on document content
- Supports PDF, TXT, and HTML
- Stateless: no DB, no storage, no reuse of past sessions
- Uses Gemini 1.5 Flash + BGE embeddings for fast and accurate results

---

## ğŸ› ï¸ Tech Stack

| Layer        | Tool/Model                       |
|--------------|----------------------------------|
| LLM          | Google Gemini 1.5 Flash          |
| Embeddings   | BAAI/bge-large-en-v1.5           |
| Vector Store | Chroma (in-memory)               |
| Backend      | Flask                            |
| Document Parsing | LangChain Community Loaders  |
| Frontend     | Simple HTML + JavaScript         |
